{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from joblib import dump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = ['binary_cic_ids_2017', 'cic_ids_2017', 'binary_nsl_kdd', 'nsl_kdd', 'binary_unsw_nb15', 'unsw_nb15']\n",
        "\n",
        "dataset = datasets[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifiers = ['AB', 'KNN', 'LDA', 'LR', 'NB', 'RF']\n",
        "\n",
        "classifier = classifiers[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xxwfZxRWFfd"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(f\"../datasets-tratados/{dataset}_train_normalized.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \"Splitting into X and y\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = train.iloc[:, :-1]\n",
        "y_train = train.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if classifier == classifiers[0]:\n",
        "    # Create a base model (e.g., a weak decision tree)\n",
        "    base_model = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "    # Create an AdaBoost model using the base model\n",
        "    model = AdaBoostClassifier(base_model, n_estimators=50, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## k-NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if classifier == classifiers[1]:\n",
        "    # Create a k-NN model\n",
        "    k_value = 3\n",
        "    model = KNeighborsClassifier(n_neighbors=k_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if classifier == classifiers[2]:\n",
        "    # Create a Linear Discriminant Analysis model\n",
        "    model = LinearDiscriminantAnalysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if classifier == classifiers[3]:\n",
        "    # Create a Logistic Regression model\n",
        "    model = LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if classifier == classifiers[4]:\n",
        "    # Create a Naive Bayes model\n",
        "    model = MultinomialNB()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if classifier == classifiers[5]:\n",
        "    # Create a Random Forest model\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the number of folds (k)\n",
        "num_folds = 5\n",
        "\n",
        "# Create a KFold object\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Start time\n",
        "start_time_cv = time.time()\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
        "\n",
        "# End time\n",
        "end_time_cv = time.time()\n",
        "cv_time = end_time_cv - start_time_cv\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean of the scores:\", cv_scores.mean())\n",
        "print(\"Standard deviation of the scores:\", cv_scores.std())\n",
        "\n",
        "print(f\"Cross-Validation Time: {cv_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start time\n",
        "start_time_train = time.time()\n",
        "\n",
        "# Training\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# End time\n",
        "end_time_train = time.time()\n",
        "training_time = end_time_train - start_time_train\n",
        "\n",
        "print(f\"Training Time: {training_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding the cross-validation scores to a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to load the CSV file\n",
        "try:\n",
        "    cv_results = pd.read_csv(f\"../results/{dataset}_cross_validation.csv\")\n",
        "except:\n",
        "    # If the file does not exist, create an empty DataFrame\n",
        "    cv_results = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_line = pd.DataFrame({'Classifier': [f'{classifier}'], 'Score1': round(cv_scores[0], 4),\n",
        "                         'Score2': round(cv_scores[1], 4), 'Score3': round(cv_scores[2], 4),\n",
        "                         'Score4': round(cv_scores[3], 4), 'Score5': round(cv_scores[4], 4),\n",
        "                         'Mean': round(cv_scores.mean(), 4), 'Standard Deviation': round(cv_scores.std(), 4)})\n",
        "\n",
        "cv_results = pd.concat([cv_results, new_line], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Saving the DataFrame\n",
        "cv_results.to_csv(f\"../results/{dataset}_cross_validation.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \"Adding the elapsed times to a DataFrame\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to load the CSV file\n",
        "try:\n",
        "    times = pd.read_csv(f\"../results/{dataset}_times.csv\")\n",
        "except:\n",
        "    # If the file does not exist, create an empty DataFrame\n",
        "    times = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_line = pd.DataFrame({'Classifier': [f'{classifier}'],\n",
        "                         'Cross-Validation': round(cv_time, 4),\n",
        "                         'Training': round(training_time, 4)})\n",
        "\n",
        "times = pd.concat([times, new_line], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Saving the DataFrame\n",
        "times.to_csv(f\"../results/{dataset}_times.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \"Saving the trained model to a file\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dump(model, f\"../trained-models/{dataset}_{classifier}.joblib\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "318f2c383d48220c821fefd227250c35bb828f95042f5889a5ad1704b1baf79c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
