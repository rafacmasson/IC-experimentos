{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pre_processing_functions import (\n",
        "    create_nslkdd_groups, remove_attributes, handle_categorical_values, handle_categoricals, normalize\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = ['cic_ids_2017', 'nsl_kdd', 'unsw_nb15']\n",
        "\n",
        "dataset = datasets[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xxwfZxRWFfd"
      },
      "outputs": [],
      "source": [
        "df =  pd.read_csv(f\"../untreated-datasets/{dataset}.csv\")\n",
        "# train = pd.read_csv(f\"../untreated-datasets/{dataset}_train.csv\")\n",
        "# test = pd.read_csv(f\"../untreated-datasets/{dataset}_test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train, test = train_test_split(df, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = create_nslkdd_groups(train)\n",
        "test = create_nslkdd_groups(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes = ['difficulty', 'num_outbound_cmds']\n",
        "\n",
        "train = remove_attributes(train, attributes)\n",
        "\n",
        "test = remove_attributes(test, attributes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes = ['service']\n",
        "\n",
        "train = handle_categorical_values(train, attributes)\n",
        "test = handle_categorical_values(test, attributes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of categorical columns\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "\n",
        "df = pd.concat([train, test], ignore_index=True)\n",
        "\n",
        "df = handle_categoricals(df, categorical_columns)\n",
        "\n",
        "train = df[:len(train)]\n",
        "test = df[len(train):]\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transforming the datasets for binary classification (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# binary_train = train.copy()\n",
        "# binary_train['label'] = binary_train['grupo'].map(lambda a: 'normal' if a == 'normal' else 'attack')\n",
        "# binary_train.drop(['grupo'],axis=1,inplace=True)\n",
        "\n",
        "# binary_test = test.copy()\n",
        "# binary_test['label'] = binary_test['grupo'].map(lambda a: 'normal' if a == 'normal' else 'attack')\n",
        "# binary_test.drop(['grupo'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating a file for the datasets without normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train.to_csv(f\"../processed-datasets/{dataset}_train_processed.csv\", index=False)\n",
        "test.to_csv(f\"../processed-datasets/{dataset}_test_processed.csv\", index=False)\n",
        "\n",
        "# binary_train.to_csv(f\"../processed-datasets/binary_{dataset}_train_processed.csv\", index=False)\n",
        "# binary_test.to_csv(f\"../processed-datasets/binary_{dataset}_test_processed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train, test = normalize(train, test)\n",
        "\n",
        "# binary_train, binary_test = normalize(binary_train, binary_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating a file for the normalized datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train.to_csv(f\"../processed-datasets/{dataset}_train_normalized.csv\", index=False)\n",
        "test.to_csv(f\"../processed-datasets/{dataset}_test_normalized.csv\", index=False)\n",
        "\n",
        "# binary_train.to_csv(f\"../processed-datasets/binary_{dataset}_train_normalized.csv\", index=False)\n",
        "# binary_test.to_csv(f\"../processed-datasets/binary_{dataset}_test_normalized.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "318f2c383d48220c821fefd227250c35bb828f95042f5889a5ad1704b1baf79c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
